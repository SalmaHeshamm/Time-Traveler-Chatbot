from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_community.vectorstores import FAISS
from langchain_groq import ChatGroq
from langchain.prompts import PromptTemplate
from langchain.schema import Document
from langchain.schema.retriever import BaseRetriever
from langchain.retrievers import EnsembleRetriever
from langchain_community.retrievers import BM25Retriever
from langchain.chains import RetrievalQA
from langchain.callbacks.manager import CallbackManagerForRetrieverRun
from typing import List, Dict
import os
from dotenv import load_dotenv
from pathlib import Path
import pickle

load_dotenv()


class MultiEraEgyptianRAG:
    """
    Ù†Ø¸Ø§Ù… RAG Ù…ØªØ¹Ø¯Ø¯ Ø§Ù„Ø¹ØµÙˆØ± Ù„Ù„ØªØ§Ø±ÙŠØ® Ø§Ù„Ù…ØµØ±ÙŠ
    ÙŠØ¯Ø¹Ù…: Ø§Ù„ÙØ±Ø¹ÙˆÙ†ÙŠØŒ Ø§Ù„ÙˆØ³Ø·Ù‰ØŒ Ø§Ù„ÙŠÙˆÙ†Ø§Ù†ÙŠØŒ Ø§Ù„Ø±ÙˆÙ…Ø§Ù†ÙŠ
    """
    
    ERAS = {
        '1': {'name': 'pharaonic', 'name_ar': 'Ø§Ù„ÙØ±Ø¹ÙˆÙ†ÙŠ', 'emoji': 'ğŸ›ï¸'},
        '2': {'name': 'medieval', 'name_ar': 'Ø§Ù„ÙˆØ³Ø·Ù‰', 'emoji': 'ğŸ•Œ'},
        '3': {'name': 'greek', 'name_ar': 'Ø§Ù„ÙŠÙˆÙ†Ø§Ù†ÙŠ', 'emoji': 'ğŸº'},
        '4': {'name': 'roman', 'name_ar': 'Ø§Ù„Ø±ÙˆÙ…Ø§Ù†ÙŠ', 'emoji': 'ğŸŸï¸'}
    }
    
    def __init__(self, model_name='sentence-transformers/paraphrase-multilingual-mpnet-base-v2', 
                 chunk_size=500, chunk_overlap=150, parent_chunk_size=2000):
        """ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ù†Ø¸Ø§Ù… Ù…Ø¹ Ø¯Ø¹Ù… Ø§Ù„Ø¹ØµÙˆØ± Ø§Ù„Ù…ØªØ¹Ø¯Ø¯Ø©"""
        self.model_name = model_name
        self.chunk_size = chunk_size
        self.chunk_overlap = chunk_overlap
        self.parent_chunk_size = parent_chunk_size
        
        # ØªØ®Ø²ÙŠÙ† Ù…Ù†ÙØµÙ„ Ù„ÙƒÙ„ Ø¹ØµØ±
        self.era_data = {
            'pharaonic': self._init_era_structure(),
            'medieval': self._init_era_structure(),
            'greek': self._init_era_structure(),
            'roman': self._init_era_structure()
        }
        
        self.current_era = None  # Ø§Ù„Ø¹ØµØ± Ø§Ù„Ø­Ø§Ù„ÙŠ Ø§Ù„Ù†Ø´Ø·
        self.embeddings = None
        
        self.llm = ChatGroq(
            groq_api_key=os.getenv("GROQ_API_KEY"),
            model_name="llama-3.1-8b-instant",
            temperature=0.1,
            max_tokens=2000
        )
        
    def _init_era_structure(self):
        """Ø¥Ù†Ø´Ø§Ø¡ Ù‡ÙŠÙƒÙ„ Ø¨ÙŠØ§Ù†Ø§Øª Ù„ÙƒÙ„ Ø¹ØµØ±"""
        return {
            'vectorstore': None,
            'bm25_retriever': None,
            'ensemble_retriever': None,
            'qa_chain': None,
            'child_documents': [],
            'parent_documents': [],
            'chunk_to_parent_map': {},
            'loaded': False
        }
    
    def load_text_file(self, file_path):
        """ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Øµ Ù…Ù† Ù…Ù„Ù"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                return f.read()
        except UnicodeDecodeError:
            with open(file_path, 'r', encoding='latin-1') as f:
                return f.read()
    
    def build_era_knowledge_base(self, era_name, file_path):
        """Ø¨Ù†Ø§Ø¡ Ù‚Ø§Ø¹Ø¯Ø© Ù…Ø¹Ø±ÙÙŠØ© Ù„Ø¹ØµØ± Ù…Ø¹ÙŠÙ†"""
        if era_name not in self.era_data:
            raise ValueError(f"Ø¹ØµØ± ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙ: {era_name}")
        
        era = self.era_data[era_name]
        emoji = next(e['emoji'] for e in self.ERAS.values() if e['name'] == era_name)
        name_ar = next(e['name_ar'] for e in self.ERAS.values() if e['name'] == era_name)
        
        print(f"\n{emoji} Ø¨Ù†Ø§Ø¡ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ù…Ø¹Ø±ÙØ© Ù„Ù„Ø¹ØµØ± {name_ar}...")
        print(f"ğŸ“š ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Øµ Ù…Ù† {file_path}...")
        
        text = self.load_text_file(file_path)
        
        print(f"âœ‚ï¸  ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ù†Øµ Ø¨Ù†Ø¸Ø§Ù… Parent-Child...")
        
        # Ø¥Ù†Ø´Ø§Ø¡ Parent chunks
        parent_splitter = RecursiveCharacterTextSplitter(
            chunk_size=self.parent_chunk_size,
            chunk_overlap=400,
            length_function=len,
            separators=["\n\n\n", "\n\n", "\n", ". ", "! ", "? ", "ØŒ ", "Ø› ", " "],
            keep_separator=True
        )
        
        parent_docs = parent_splitter.create_documents([text])
        
        # Ø¥Ù†Ø´Ø§Ø¡ Child chunks
        child_splitter = RecursiveCharacterTextSplitter(
            chunk_size=self.chunk_size,
            chunk_overlap=self.chunk_overlap,
            length_function=len,
            separators=["\n\n", "\n", ". ", "! ", "? ", "ØŒ ", "Ø› ", " "],
            keep_separator=True
        )
        
        # Ø±Ø¨Ø· Parent-Child
        for parent_idx, parent_doc in enumerate(parent_docs):
            children = child_splitter.split_documents([parent_doc])
            
            for child_idx, child in enumerate(children):
                child.metadata['parent_idx'] = parent_idx
                child.metadata['child_idx'] = child_idx
                child.metadata['chunk_id'] = f"{era_name}_p{parent_idx}_c{child_idx}"
                child.metadata['era'] = era_name
                
                era['child_documents'].append(child)
                era['chunk_to_parent_map'][child.metadata['chunk_id']] = parent_doc
        
        era['parent_documents'] = parent_docs
        
        print(f"   âœ… {len(parent_docs)} parent chunks")
        print(f"   âœ… {len(era['child_documents'])} child chunks")
        
        # Ø¥Ø¹Ø¯Ø§Ø¯ Retrievers
        print(f"ğŸ§  Ø¥Ø¹Ø¯Ø§Ø¯ Ù†Ø¸Ø§Ù… Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ù‡Ø¬ÙŠÙ†...")
        
        # BM25
        era['bm25_retriever'] = BM25Retriever.from_documents(era['child_documents'])
        era['bm25_retriever'].k = 6
        
        # Embeddings & FAISS
        if self.embeddings is None:
            print(f"   ğŸ“Š Ø¥Ù†Ø´Ø§Ø¡ Ù†Ù…ÙˆØ°Ø¬ Embeddings...")
            self.embeddings = HuggingFaceEmbeddings(
                model_name=self.model_name,
                model_kwargs={'device': 'cpu'},
                encode_kwargs={'normalize_embeddings': True}
            )
        
        era['vectorstore'] = FAISS.from_documents(era['child_documents'], self.embeddings)
        faiss_retriever = era['vectorstore'].as_retriever(search_kwargs={"k": 6})
        
        # Ensemble
        era['ensemble_retriever'] = EnsembleRetriever(
            retrievers=[era['bm25_retriever'], faiss_retriever],
            weights=[0.4, 0.6]
        )
        
        # QA Chain
        self._setup_era_qa_chain(era_name)
        
        era['loaded'] = True
        print(f"âœ… Ù‚Ø§Ø¹Ø¯Ø© Ù…Ø¹Ø±ÙØ© Ø§Ù„Ø¹ØµØ± {name_ar} Ø¬Ø§Ù‡Ø²Ø©!\n")
    
    def _expand_context(self, era_name, retrieved_docs, num_neighbors=1):
        """ØªÙˆØ³ÙŠØ¹ Ø§Ù„Ø³ÙŠØ§Ù‚ Ø¨Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ø£Ø¬Ø²Ø§Ø¡ Ø§Ù„Ù…Ø¬Ø§ÙˆØ±Ø©"""
        era = self.era_data[era_name]
        expanded_docs = []
        seen_chunks = set()
        
        for doc in retrieved_docs:
            parent_idx = doc.metadata.get('parent_idx')
            child_idx = doc.metadata.get('child_idx')
            chunk_id = doc.metadata.get('chunk_id')
            
            if chunk_id in seen_chunks:
                continue
            
            # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ø£Ø¬Ø²Ø§Ø¡ Ø§Ù„Ù…Ø¬Ø§ÙˆØ±Ø©
            neighbors = []
            for offset in range(-num_neighbors, num_neighbors + 1):
                neighbor_id = f"{era_name}_p{parent_idx}_c{child_idx + offset}"
                
                for child_doc in era['child_documents']:
                    if child_doc.metadata.get('chunk_id') == neighbor_id:
                        if neighbor_id not in seen_chunks:
                            neighbors.append(child_doc)
                            seen_chunks.add(neighbor_id)
                        break
            
            if neighbors:
                expanded_docs.extend(neighbors)
            else:
                parent_doc = era['chunk_to_parent_map'].get(chunk_id)
                if parent_doc:
                    expanded_doc = Document(
                        page_content=parent_doc.page_content,
                        metadata={'source': 'parent_context', **doc.metadata}
                    )
                    expanded_docs.append(expanded_doc)
        
        return expanded_docs[:8]
    
    def _setup_era_qa_chain(self, era_name):
        """Ø¥Ø¹Ø¯Ø§Ø¯ QA chain Ù„Ø¹ØµØ± Ù…Ø¹ÙŠÙ†"""
        era = self.era_data[era_name]
        name_ar = next(e['name_ar'] for e in self.ERAS.values() if e['name'] == era_name)
        
        template = f"""Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ Ø®Ø¨ÙŠØ± ÙÙŠ Ø§Ù„ØªØ§Ø±ÙŠØ® Ø§Ù„Ù…ØµØ±ÙŠ - Ø§Ù„Ø¹ØµØ± {name_ar}.

âš ï¸ Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©:
1. Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ù…Ù† Ø§Ù„Ø³ÙŠØ§Ù‚ Ø§Ù„Ù…ÙˆØ³Ø¹ Ø£Ø¯Ù†Ø§Ù‡
2. Ø§Ù„Ø³ÙŠØ§Ù‚ ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø£Ø¬Ø²Ø§Ø¡ Ù…ØªØ±Ø§Ø¨Ø·Ø© - Ø§Ø³ØªØ®Ø¯Ù…Ù‡Ø§ Ù…Ø¹Ø§Ù‹
3. Ø£Ø¬Ø¨ Ø¨Ø´ÙƒÙ„ Ù…ÙØµÙ„ ÙˆØ´Ø§Ù…Ù„ Ø¹Ù† Ø§Ù„Ø¹ØµØ± {name_ar}
4. Ø¥Ø°Ø§ Ù„Ù… ØªØ¬Ø¯ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø© ÙÙŠ Ø§Ù„Ø³ÙŠØ§Ù‚ØŒ Ù‚Ù„: "Ù‡Ø°Ù‡ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø© ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯Ø© ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¹ØµØ± {name_ar}"
5. Ø§Ø±Ø¨Ø· Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ù…Ù† Ø£Ø¬Ø²Ø§Ø¡ Ù…Ø®ØªÙ„ÙØ© Ù„Ø¥Ø¹Ø·Ø§Ø¡ Ø¥Ø¬Ø§Ø¨Ø© ÙƒØ§Ù…Ù„Ø©

Ø§Ù„Ø³ÙŠØ§Ù‚ Ø§Ù„Ù…ÙˆØ³Ø¹:
==================
{{context}}
==================

Ø§Ù„Ø³Ø¤Ø§Ù„: {{question}}

Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©:"""

        PROMPT = PromptTemplate(
            template=template,
            input_variables=["context", "question"]
        )
        
        # Custom Retriever Ù…Ø¹ ØªÙˆØ³ÙŠØ¹ Ø§Ù„Ø³ÙŠØ§Ù‚
        class ContextExpandedRetriever(BaseRetriever):
            base_retriever: object
            expand_fn: object
            
            class Config:
                arbitrary_types_allowed = True
            
            def _get_relevant_documents(
                self, query: str, *, run_manager: CallbackManagerForRetrieverRun = None
            ) -> List[Document]:
                base_docs = self.base_retriever.get_relevant_documents(query)
                return self.expand_fn(base_docs, num_neighbors=1)
        
        expanded_retriever = ContextExpandedRetriever(
            base_retriever=era['ensemble_retriever'],
            expand_fn=lambda docs, num_neighbors: self._expand_context(era_name, docs, num_neighbors)
        )
        
        era['qa_chain'] = RetrievalQA.from_chain_type(
            llm=self.llm,
            chain_type="stuff",
            retriever=expanded_retriever,
            return_source_documents=True,
            chain_type_kwargs={"prompt": PROMPT}
        )
    
    def save_all_eras(self, base_dir="knowledge_base"):
        """Ø­ÙØ¸ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø¹ØµÙˆØ±"""
        Path(base_dir).mkdir(exist_ok=True)
        
        for era_name, era in self.era_data.items():
            if not era['loaded']:
                continue
            
            era_dir = f"{base_dir}/{era_name}"
            Path(era_dir).mkdir(exist_ok=True)
            
            # Ø­ÙØ¸ FAISS
            era['vectorstore'].save_local(f"{era_dir}/faiss_index")
            
            # Ø­ÙØ¸ Ø§Ù„Ù…Ø³ØªÙ†Ø¯Ø§Øª
            with open(f"{era_dir}/documents.pkl", 'wb') as f:
                pickle.dump({
                    'child_documents': era['child_documents'],
                    'parent_documents': era['parent_documents'],
                    'chunk_to_parent_map': era['chunk_to_parent_map']
                }, f)
        
        # Ø­ÙØ¸ Ø§Ù„ØªÙƒÙˆÙŠÙ† Ø§Ù„Ø¹Ø§Ù…
        with open(f"{base_dir}/config.pkl", 'wb') as f:
            pickle.dump({
                'model_name': self.model_name,
                'chunk_size': self.chunk_size,
                'chunk_overlap': self.chunk_overlap,
                'parent_chunk_size': self.parent_chunk_size
            }, f)
        
        print(f"ğŸ’¾ ØªÙ… Ø­ÙØ¸ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø¹ØµÙˆØ± ÙÙŠ {base_dir}/")
    
    def load_all_eras(self, base_dir="knowledge_base"):
        """ØªØ­Ù…ÙŠÙ„ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø¹ØµÙˆØ±"""
        # ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØªÙƒÙˆÙŠÙ†
        with open(f"{base_dir}/config.pkl", 'rb') as f:
            config = pickle.load(f)
            self.model_name = config['model_name']
            self.chunk_size = config['chunk_size']
            self.chunk_overlap = config['chunk_overlap']
            self.parent_chunk_size = config['parent_chunk_size']
        
        # ØªØ­Ù…ÙŠÙ„ Embeddings
        if self.embeddings is None:
            self.embeddings = HuggingFaceEmbeddings(
                model_name=self.model_name,
                model_kwargs={'device': 'cpu'},
                encode_kwargs={'normalize_embeddings': True}
            )
        
        # ØªØ­Ù…ÙŠÙ„ ÙƒÙ„ Ø¹ØµØ±
        for era_name in self.era_data.keys():
            era_dir = f"{base_dir}/{era_name}"
            
            if not os.path.exists(era_dir):
                continue
            
            era = self.era_data[era_name]
            
            # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ø³ØªÙ†Ø¯Ø§Øª
            with open(f"{era_dir}/documents.pkl", 'rb') as f:
                data = pickle.load(f)
                era['child_documents'] = data['child_documents']
                era['parent_documents'] = data['parent_documents']
                era['chunk_to_parent_map'] = data['chunk_to_parent_map']
            
            # ØªØ­Ù…ÙŠÙ„ FAISS
            era['vectorstore'] = FAISS.load_local(
                f"{era_dir}/faiss_index",
                self.embeddings,
                allow_dangerous_deserialization=True
            )
            
            # Ø¥Ø¹Ø§Ø¯Ø© Ø¨Ù†Ø§Ø¡ Retrievers
            era['bm25_retriever'] = BM25Retriever.from_documents(era['child_documents'])
            era['bm25_retriever'].k = 6
            
            faiss_retriever = era['vectorstore'].as_retriever(search_kwargs={"k": 6})
            era['ensemble_retriever'] = EnsembleRetriever(
                retrievers=[era['bm25_retriever'], faiss_retriever],
                weights=[0.4, 0.6]
            )
            
            self._setup_era_qa_chain(era_name)
            era['loaded'] = True
        
        print(f"âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø¹ØµÙˆØ± Ø§Ù„Ù…ØªØ§Ø­Ø©!")
    
    def switch_era(self, era_name):
        """Ø§Ù„ØªØ¨Ø¯ÙŠÙ„ Ø¥Ù„Ù‰ Ø¹ØµØ± Ù…Ø¹ÙŠÙ†"""
        if era_name not in self.era_data:
            return False
        
        if not self.era_data[era_name]['loaded']:
            return False
        
        self.current_era = era_name
        return True
    
    def ask(self, query, era_name=None, return_sources=False):
        """Ø·Ø±Ø­ Ø³Ø¤Ø§Ù„ Ø¹Ù„Ù‰ Ø¹ØµØ± Ù…Ø¹ÙŠÙ†"""
        if era_name:
            self.switch_era(era_name)
        
        if self.current_era is None:
            raise Exception("Ù„Ù… ÙŠØªÙ… Ø§Ø®ØªÙŠØ§Ø± Ø¹ØµØ±. Ø§Ø³ØªØ®Ø¯Ù… switch_era() Ø£ÙˆÙ„Ø§Ù‹")
        
        era = self.era_data[self.current_era]
        
        if era['qa_chain'] is None:
            raise Exception(f"Ù‚Ø§Ø¹Ø¯Ø© Ù…Ø¹Ø±ÙØ© Ø§Ù„Ø¹ØµØ± {self.current_era} ØºÙŠØ± Ø¬Ø§Ù‡Ø²Ø©")
        
        result = era['qa_chain'].invoke({"query": query})
        
        response = {
            'answer': result['result'],
            'source_documents': result['source_documents'],
            'era': self.current_era
        }
        
        return response if return_sources else response['answer']
    
    def get_loaded_eras(self):
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø¹ØµÙˆØ± Ø§Ù„Ù…Ø­Ù…Ù„Ø©"""
        return [name for name, era in self.era_data.items() if era['loaded']]
    
    def display_main_menu(self):
        """Ø¹Ø±Ø¶ Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©"""
        print("\n" + "="*70)
        print("ğŸº Ù†Ø¸Ø§Ù… RAG Ù„Ù„ØªØ§Ø±ÙŠØ® Ø§Ù„Ù…ØµØ±ÙŠ Ø¹Ø¨Ø± Ø§Ù„Ø¹ØµÙˆØ±")
        print("="*70)
        
        loaded_eras = self.get_loaded_eras()
        
        if not loaded_eras:
            print("âŒ Ù„Ù… ÙŠØªÙ… ØªØ­Ù…ÙŠÙ„ Ø£ÙŠ Ø¹ØµØ±!")
            print("Ø§Ø³ØªØ®Ø¯Ù… build_era_knowledge_base() Ø£ÙˆÙ„Ø§Ù‹")
            return
        
        print("\nğŸ“š Ø§Ù„Ø¹ØµÙˆØ± Ø§Ù„Ù…ØªØ§Ø­Ø©:")
        for key, info in self.ERAS.items():
            if info['name'] in loaded_eras:
                era = self.era_data[info['name']]
                status = "âœ…" if self.current_era == info['name'] else "  "
                print(f"{status} [{key}] {info['emoji']} {info['name_ar']}")
                print(f"      â””â”€ {len(era['child_documents'])} chunks")
        
        print("\nğŸ¯ Ø§Ù„Ø£ÙˆØ§Ù…Ø±:")
        print("   [1-4] - Ø§Ø®ØªØ± Ø¹ØµØ±Ø§Ù‹")
        print("   'Ù‚Ø§Ø¦Ù…Ø©' - Ø¹Ø±Ø¶ Ø§Ù„Ù‚Ø§Ø¦Ù…Ø©")
        print("   'Ø®Ø±ÙˆØ¬' - Ø¥Ù†Ù‡Ø§Ø¡")
        print("="*70)
    
    def chat(self):
        """ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© Ø§Ù„ØªÙØ§Ø¹Ù„ÙŠØ©"""
        self.display_main_menu()
        
        while True:
            try:
                # Ø¹Ø±Ø¶ Ø§Ù„Ø¹ØµØ± Ø§Ù„Ø­Ø§Ù„ÙŠ
                if self.current_era:
                    emoji = next(e['emoji'] for e in self.ERAS.values() if e['name'] == self.current_era)
                    name_ar = next(e['name_ar'] for e in self.ERAS.values() if e['name'] == self.current_era)
                    prompt = f"\n{emoji} [{name_ar}] Ø£Ù†Øª: "
                else:
                    prompt = "\nâ“ Ø§Ø®ØªØ± Ø¹ØµØ±Ø§Ù‹ Ø£ÙˆÙ„Ø§Ù‹: "
                
                user_input = input(prompt).strip()
                
                if not user_input:
                    continue
                
                # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø£ÙˆØ§Ù…Ø±
                if user_input.lower() in ['quit', 'exit', 'Ø®Ø±ÙˆØ¬', 'q']:
                    print("\nğŸ‘‹ Ø´ÙƒØ±Ø§Ù‹ Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…Ùƒ Ø§Ù„Ù†Ø¸Ø§Ù…. ÙˆØ¯Ø§Ø¹Ø§Ù‹!")
                    break
                
                if user_input in ['Ù‚Ø§Ø¦Ù…Ø©', 'menu', 'm']:
                    self.display_main_menu()
                    continue
                
                # Ø§Ù„ØªØ¨Ø¯ÙŠÙ„ Ø¨ÙŠÙ† Ø§Ù„Ø¹ØµÙˆØ±
                if user_input in self.ERAS:
                    era_info = self.ERAS[user_input]
                    if self.switch_era(era_info['name']):
                        print(f"\nâœ… ØªÙ… Ø§Ù„ØªØ¨Ø¯ÙŠÙ„ Ø¥Ù„Ù‰ Ø§Ù„Ø¹ØµØ± {era_info['emoji']} {era_info['name_ar']}")
                    else:
                        print(f"\nâŒ Ø§Ù„Ø¹ØµØ± {era_info['name_ar']} ØºÙŠØ± Ù…Ø­Ù…Ù‘Ù„!")
                    continue
                
                # Ø·Ø±Ø­ Ø³Ø¤Ø§Ù„
                if self.current_era is None:
                    print("âš ï¸  Ø§Ø®ØªØ± Ø¹ØµØ±Ø§Ù‹ Ø£ÙˆÙ„Ø§Ù‹! (1-4)")
                    continue
                
                print("\nğŸ” Ø¬Ø§Ø±ÙŠ Ø§Ù„Ø¨Ø­Ø«...")
                result = self.ask(user_input, return_sources=True)
                
                print(f"\nğŸ’¬ {result['answer']}\n")
                
                # Ø¹Ø±Ø¶ Ø§Ù„Ù…ØµØ§Ø¯Ø± (Ø§Ø®ØªÙŠØ§Ø±ÙŠ)
                show = input("ğŸ“š Ø¹Ø±Ø¶ Ø§Ù„Ù…ØµØ§Ø¯Ø±ØŸ (y/n): ").strip().lower()
                if show == 'y':
                    print("\n" + "="*60)
                    print("Ø§Ù„Ù…ØµØ§Ø¯Ø±:")
                    print("="*60)
                    for i, doc in enumerate(result['source_documents'][:3], 1):
                        print(f"\n[{i}] {doc.metadata.get('chunk_id', 'N/A')}")
                        print(doc.page_content[:300] + "...")
                        print("-"*40)
                
            except KeyboardInterrupt:
                print("\n\nğŸ‘‹ ÙˆØ¯Ø§Ø¹Ø§Ù‹!")
                break
            except Exception as e:
                print(f"\nâŒ Ø®Ø·Ø£: {str(e)}")


# === Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… ===
if __name__ == "__main__":
    # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù†Ø¸Ø§Ù…
    chatbot = MultiEraEgyptianRAG(
        chunk_size=500,
        chunk_overlap=150,
        parent_chunk_size=2000
    )
    
    # Ù‡ÙŠÙƒÙ„ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…ØªÙˆÙ‚Ø¹:
    era_files = {
        'pharaonic': 'data/pharaonic/pharaonic_info.txt',
        'medieval': 'data/medieval/medieval_info.txt',
        'greek': 'data/greek/greek_info.txt',
        'roman': 'data/roman/roman_info.txt'
    }
    
    # Ø¨Ù†Ø§Ø¡ Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ù…Ø¹Ø±ÙØ© (Ù…Ø±Ø© ÙˆØ§Ø­Ø¯Ø© ÙÙ‚Ø·)
    print("ğŸš€ Ø¨Ø¯Ø¡ Ø¨Ù†Ø§Ø¡ Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ù…Ø¹Ø±ÙØ©...\n")
    
    for era_name, file_path in era_files.items():
        if os.path.exists(file_path):
            chatbot.build_era_knowledge_base(era_name, file_path)
        else:
            print(f"âš ï¸  Ù…Ù„Ù {era_name} ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯: {file_path}")
    
    # Ø­ÙØ¸ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø¹ØµÙˆØ±
    chatbot.save_all_eras()
    
    # Ø£Ùˆ ØªØ­Ù…ÙŠÙ„ Ù…Ù† Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ø­ÙÙˆØ¸Ø©:
    # chatbot.load_all_eras()
    
    # Ø§Ø®ØªÙŠØ§Ø± Ø¹ØµØ± Ø§ÙØªØ±Ø§Ø¶ÙŠ
    if chatbot.get_loaded_eras():
        chatbot.switch_era(chatbot.get_loaded_eras()[0])
    
    # Ø¨Ø¯Ø¡ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©
    chatbot.chat()